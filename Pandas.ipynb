{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicas da Biblioteca Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar a biblioteca Pandas e Importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando a biblioteca\n",
    "# pip install pandas\n",
    "# ou\n",
    "# pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org pip pandas\n",
    "\n",
    "# Importando a biblioteca pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veja 3 formas de criar um mesmo dataframe do zero com dados inciais\n",
    "dados = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "df1 = pd.DataFrame(dados, columns=['a', 'b', 'c'])\n",
    "print(df1)\n",
    "print()\n",
    "\n",
    "\n",
    "dados = {'a': [1,4,7], 'b':[2,5,8], 'c': [3,6,9]}\n",
    "df2 = pd.DataFrame(dados)\n",
    "print(df2)\n",
    "print()\n",
    "\n",
    "\n",
    "dados = [{'a': 1, 'b': 2, 'c': 3}, {'a': 4, 'b': 5, 'c': 6}, {'a': 7, 'b': 8, 'c': 9}]\n",
    "df3 = pd.DataFrame(dados)\n",
    "print(df3)\n",
    "print()\n",
    "\n",
    "##############################################################################\n",
    "# criar dataframe vazio, sem a coluna indice de linhas\n",
    "df = pd.DataFrame(index= None)\n",
    "\n",
    "# criar dataframe a partir do excel xls (requisito: pip install xlrd)\n",
    "df = pd.read_excel(\"C:\\\\Temp\\\\planilha.xls\", engine=\"xlrd\", sheet_name=0 )\n",
    "\n",
    "# criar dataframe a partir do excel xlsx\n",
    "df = pd.read_excel(\"C:\\\\Temp\\\\planilha.xlsx\")\n",
    "\n",
    "# criar dataframe a partir do excel xlsx, selecionando a guia da planilha, e limitando num_linhas que vai ler\n",
    "df = pd.read_excel(\"C:\\\\Temp\\\\planilha.xlsx\", sheet_name=0, nrows=10)\n",
    "df = pd.read_excel(\"C:\\\\Temp\\\\planilha.xlsx\", sheet_name='Plan1', nrows=10)\n",
    "\n",
    "# criar dataframe, ignorando as 10 primeiras linhas (skiprows), usando converters para preencher com zeros a esquerda a coluna CPF e CNPJ\n",
    "df3 = pd.read_excel(\"C:\\\\Temp\\\\planilha.xlsx\", sheet_name=0, skiprows=range(0, 10), converters={'CNPJ da Instituição': '{:0>14}'.format, 'CPF': '{:0>11}'.format})\n",
    "\n",
    "\n",
    "# criar dataframe a partir de arquivo CSV, defina qual o separador('' ou ',' ou ';')\n",
    "df = pd.read_csv(\"C:\\\\Temp\\\\file.csv\", sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalhando com as colunas do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter lista de nomes das colunas\n",
    "colunas = df3_dados_iniciais.columns.values.tolist() \n",
    "\n",
    "# reordenar colunas  pelo nome da coluna, ou filtrar apenas as colunas desejadas\n",
    "df = df[[\"Nr.Contrato do Convênio\", \"Vl.Descontado\", \"Cód.Verba\", \"Data\", \"CPF\", \"Matrícula\", \"Nome\"]]\n",
    "\n",
    "# deletar colunas\n",
    "#drop one column by name\n",
    "df.drop('column_name', axis=1, inplace=True)\n",
    "\n",
    "#drop multiple columns by name\n",
    "df.drop(['column_name1', 'column_name2'], axis=1, inplace=True)\n",
    "\n",
    "#drop one column by index\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "#drop multiple columns by index\n",
    "df.drop(df.columns[[0,2,5]], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# selecionar parcialmente 2 colunas\n",
    "novo_df = df[['nome_coluna3','nome_coluna5']])\n",
    "\n",
    "# adicionar nova coluna  'nova1' no final das colunas existentes, e com valor '0'\n",
    "df['nova1'] = '0'\n",
    "  \n",
    "# adicionar nova coluna 'nova2' na posicao coluna 15, com valor padrão '0' em todas a linhas\n",
    "df.insert(loc=15, column='nova2', value='0')\n",
    "\n",
    "# renomear o titulo da coluna: exemplo de nome 'data lançamento' para novo nome 'data_lanc'\n",
    "df.rename(columns={'data lançamento': 'data_lanc'}, inplace=True)\n",
    "  \n",
    "# converte toda a coluna para um tipo de dados específico, exemplos abaixo\n",
    "df['SALDO'] = df['SALDO'].astype(int)  \n",
    "df['DESCRICAO'] = df['DESCRICAO'].astype(str)\n",
    "df['DATA_VCTO'] = df['DATA_VCTO'].astype('datetime64[ns]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrair uma célula do DataFrame para String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar string, ou lista de string\n",
    "cpf_cnpj = df.iloc[0,:].to_string(header=False, index=False)\n",
    "     \n",
    "variavel_string = df_campos.loc[df_campos['id'] == '5171', 'valor'].item()\n",
    "variavel_string = df_campos.loc[df_campos['id'] == '5171', 'valor'][0]\n",
    "variavel_string = df_campos.loc[df_campos['id'] == '5171', 'valor'][1]\n",    
    "variavel_string = df_campos.loc[df_campos['id'] == '5171', 'valor'].to_string(header=False, index=False)\n",

    "    \n",
    "arr = df.iloc[0,:].apply(str).values\n",
    "cpf_cnpj = arr[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesquisa por referencia, condição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo: pesquisa se o valor da coluna [ID] == 2012, se encontrar me retorne valor da coluna [cpf] na mesma linha do ID 2012\n",
    "variavel_cpf = df.query('id==2012')['cpf'].values[0]\n",
    "\n",
    "# trocando valor em linhas da coluna, baseado em condição, se na coluna data tiver 'qualquer coisa + 2021', troca o valor por um novo_valor\n",
    "df['Data'] = df.Data.str.replace(r'(.*2021)', 'novo_valor')\n",
    "# novo metodo replace(to_replace...)\n",
    "df['tel_associado'].replace(to_replace=r\"^(0+)\", value=\"\", inplace=True, regex=True)\n",
    "\n",
    "# localiza no dataframe na coluna data, os campos cuja 6ª posicao até o fim é = 2021\n",
    "# se envontrar, troca o valor da coluna CPF por um novo_valor ( cpf + ok )\n",
    "df.loc[df.Data.str[6:]=='2021','CPF']= df.CPF + ' ok'\n",
    "\n",
    "# exemplo se localizar linhas com valor 'apple' na coluna_a, substituir o valor da coluna_b na mesma linha (neste caso novo valor='0')\n",
    "df.loc[df['coluna_a'] == 'apple', 'coluna_b'].replace(r'0', 'novo_valor',inplace=True, regex=True)\n",
    "\n",
    "# outro exemplo de localizar e substituir (neste exemplo substitui o ponto por vazio, em seguida substitui a virgula por ponto)\n",
    "df['valor'] = df['valor'].apply(lambda x: float(x.replace(\".\",\"\").replace(\",\",\".\")))\n",
    "\n",
    "# add valor em campo do DF, baseado na condicao do tamanho do valor de uma celula do DF\n",
    "df.loc[df.tel_associado.str.len() > 9, 'DDD'] = df.tel_associado.str[:2]\n",
    "print(df['DDD'])\n",
    "\n",
    "# exemplo de SOMASE, soma coluna baseado em condição, obs. a condição pode ser em outra coluna ou na mesma\n",
    "v1 = df[['VALOR']].sum(axis=1).where(df['CODIGO_LANCAMENTO'] == 'DEBITO', 0)\n",
    "total_deb = sum(v1)\n",
    "\n",
    "# exemplo where em dataframe, montando df2 em que possui apenas a coluna valor, cujo filtramos a coluna id do DF anterior\n",
    "id_campo = '1535'\n",
    "df1 = df[['valor']].where(df['id'] == id_campo, 0)\n",
    "filtro = df1['valor'] != 0\n",
    "df2 = df1[filtro]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substring, Update valor da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo: atualizar a coluna 'CPF' - adicionar a pontuação ( ponto e traço )\n",
    "df['CPF'] = df['CPF'].astype(str)\n",
    "df['CPF'] = df['CPF'].str[:3] + '.' + df['CPF'].str[3:6] + '.' + df['CPF'].str[6:9] + '-' + df['CPF'].str[9:11]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtros (Manter os dados no DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dias_sem_transacionar maior que 365 ou dias_sem_transacionar é null(NaN)\n",
    "df[\"dias_sem_transacionar\"] = df[\"dias_sem_transacionar\"].astype('float')\n",
    "df = df.query('(dias_sem_transacionar > 365) or (dias_sem_transacionar != dias_sem_transacionar)')\n",
    "# ou\n",
    "df = df.query('(dias_sem_transacionar > 365) or (dias_sem_transacionar.isnull())', engine='python')\n",
    "\n",
    "# filtar, manter apenas linhas em que a coluna email, contenha 'qualquer_nome@gmail.com.br', remover demais linhas do DF\n",
    "df = df.query('email.str.contains(\"@gmail.com.br\")', engine='python') # retona o valor da coluna\n",
    "# nao contains\n",
    "df = df[~df[\"produto\"].str.contains(\"POUP\")] # retorna os valores a manter nas colunas\n",
    "new_df = df[~df[\"col\"].str.contains('word')]\n",
    "new_df = df[df[\"col\"].str.contains('word') == False]\n",
    "\n",
    "df = df.email.str.contains('.*@gmail.com.br') # retorna verdadeiro ou falso\n",
    "\n",
    "# exemplos de condição para selecionar as linhas que deseja manter no DataFrame\n",
    "df2 = df.query('coluna_name_a > 50 and coluna_name_b > 80')\n",
    "df3 = df.query('coluna_name_a == \"jan\" or coluna_name_b == \"2022\"')\n",
    "\n",
    "# filtrar as linhas cujo valor da coluna 'ATRASO' esteja entre 90 e 1800 dias\n",
    "df_filtro = df['ATRASO'].between(90, 1800)  \n",
    "df2 = df[df_filtro]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros (Remover linhas do DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove as linhas do dataframe, cuja coluna CPF, conter valor duplicado, implace(em tempo real) - mantém ao menos 1 item entre os duplicados\n",
    "df.drop_duplicates(subset=['CPF'], inplace=True)  \n",
    "\n",
    "# remove as linhas do dataframe, cuja coluna CPF, conter valor duplicado, implace(em tempo real) - não mantém nenhum item dos apontados como duplicado\n",
    "df.drop_duplicates(subset=['CPF'], keep=False, inplace=True)\n",
    "\n",
    "# remove as linhas do dataframe, cuja coluna CPF, conter valor vazio ou NaN\n",
    "df.dropna(subset=['CPF'], inplace=True)\n",
    "\n",
    "# remover as linhas em que a coluna [CPF] tem o valor vazio\n",
    "filtro = df['CPF_CNPJ'] != \"\"\n",
    "df2 = df[filtro]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incrementar, empilhar linhas de dados em DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add linhas no dataframe destino df2\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for linha, valor in df.iterrows():\n",
    "    CODIGO = str(valor['CODIGO'])\n",
    "    SALDO = str(valor['SALDO'])\n",
    "    CPF_CNPJ = str(valor['CPF_CNPJ'])\n",
    "\n",
    "    df1 = pd.DataFrame([{\n",
    "        'CODIGO': CODIGO,\n",
    "        'SALDO': SALDO,\n",
    "        'CPF_CNPJ': CPF_CNPJ}], index= None)\n",
    "    df2 = pd.concat([df1, df2])\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparar 2 DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparar DataFrame 'a' com DataFrame 'b' se encontar uma linha repetida em ambos, \n",
    "# remover do DF 'a', por fim, guardar o que restar no DF 'a' no novo_df\n",
    "a = pd.DataFrame()\n",
    "b = pd.DataFrame()\n",
    "df_cartao_debito = pd.DataFrame()\n",
    "\n",
    "novo_df = (pd.merge(a,b, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)) \n",
    "\n",
    "# manter a linha no df, se o valor na coluna conta_corrente do df, esta igual ao valor conta_corrente no df_cartao_debito\n",
    "df = df[df['conta_corrente'].isin(df_cartao_debito['conta_corrente'])] \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupar DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neste exemplo abaixo vou agrupar o DF pela coluna [CPF]\n",
    "# ou seja os valores duplicados da coluna [CPF], serão indices de grupos\n",
    "# o que ocorre com os dados das demais colunas ao agrupar?\n",
    "# existem parametros para usar com o groupby, neste caso vou usar 2\n",
    "# Nas colunas [CPF] e [NOME], uso o comando 'first' que vai manter o primeiro valor encontrado \n",
    "# Nas colunas [DEBITO] e [CREDITO], uso o comando 'sum' que vai somar os valores do que foi agrupado de cada CPF \n",
    "# df.groupby(['name', 'month'], as_index = False).agg({'text': ' '.join})\n",
    "\n",
    "df2 = df.groupby(['CPF'],as_index=False).agg({\n",
    "        'CPF': 'first', 'NOME': 'first', 'DEBITO': 'sum', 'CREDITO': 'sum'\n",
    "        }) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar salvar saída do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar DF para Excel\n",
    "df.to_excel(\"C:\\\\Temp\\\\relatorio.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# Exportar DF para Excel, salvar em guias/abas diferentes no mesmo arquivo \n",
    "writer = pd.ExcelWriter(f'c:\\\\temp\\\\relatorio.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "df1.to_excel(writer, index=False, sheet_name='Plan1')\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Plan1']\n",
    "\n",
    "df2.to_excel(writer, index=False, sheet_name='Plan2')\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Plan2']\n",
    "\n",
    "df3.to_excel(writer, index=False, sheet_name='Plan3')\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Plan3']\n",
    "\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# Exportar DF para CSV\n",
    "df.to_csv(\"C:\\\\Temp\\\\relatorio.csv\", sep=';', index=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas + SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consultar MySQL e Salvar em DataFrame\n",
    "# requisitos\n",
    "# pip install mysql-connector-python\n",
    "# pip install SQLAlchemy\n",
    "# pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "##############################################################################\n",
    "# autenticando a conexao\n",
    "def conect_sql_alchemy():\n",
    "    from sqlalchemy import create_engine\n",
    "    server = 'IP ou Host aqui'\n",
    "    user_planning = 'usuario com acesso ao BD'\n",
    "    pwd_planning = os.getenv('senha_credencial_var_ambiente')\n",
    "    db = 'planning'\n",
    "    engine = create_engine(f'mysql+mysqlconnector://{user_planning}:{pwd_planning}@{server}/{db}', pool_recycle=3600)\n",
    "    return engine\n",
    "    \n",
    "##############################################################################\n",
    "# realizando a consulta, e convertendo em DataFame\n",
    "def select_movimentacao(num_conta):\n",
    "    engine = conect_sql_alchemy()\n",
    "    sql = f\"SELECT * FROM movimentacao_financeira WHERE num_conta = '{num_conta}' AND dat_operacao >= '2021-03-01 00:00:00' \" \n",
    "    df = pd.read_sql(sql, con=engine)\n",
    "    return df\n",
    "\n",
    "df = select_movimentacao('12345-6')\n",
    "print(df)\n",
    "\n",
    "##############################################################################\n",
    "## Insert SQL para DB \n",
    "def input_in_tabela_planning(df):\n",
    "    from sqlalchemy import create_engine\n",
    "    server = 'IP ou Host aqui'\n",
    "    user_planning = 'usuario com acesso ao BD'\n",
    "    pwd_planning = os.getenv('senha_credencial_var_ambiente')\n",
    "    db = 'fluid'\n",
    "    engine = create_engine(f'mysql+mysqlconnector://{user_planning}:{pwd_planning}@{server}/{db}', pool_recycle=3600)\n",
    "    df.to_sql('nome_da_tabela', engine, if_exists='append', index = False)\n",
    "    # df.to_sql('nome_da_tabela', engine, if_exists='replace', index = False)\n",
    "    print('Input realizado com sucesso no BD')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
